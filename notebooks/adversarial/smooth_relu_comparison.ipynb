{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU Formulation Comparison\n",
    "\n",
    "Compare different ReLU formulations: standard MIP (global optimal) vs. nonlinear formulations (local optimal).\n",
    "\n",
    "**Requirements:** torch, torchvision, skorch, matplotlib, gurobipy >= 12.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from skorch import NeuralNetClassifier\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from gurobi_ml import add_predictor_constr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "# Get MNIST digit recognition data set\n",
    "mnist_train = torchvision.datasets.MNIST(root=\"./MNIST\", train=True, download=True)\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST(root=\"./MNIST\", train=False, download=True)\n",
    "\n",
    "x_train = torch.flatten(mnist_train.data.type(torch.FloatTensor), start_dim=1)\n",
    "y_train = mnist_train.targets\n",
    "x_test = torch.flatten(mnist_test.data.type(torch.FloatTensor), start_dim=1)\n",
    "y_test = mnist_test.targets\n",
    "\n",
    "x_train /= 255.0  # scaling\n",
    "x_test /= 255.0  # scaling\n",
    "\n",
    "print(f\"Training samples: {len(x_train)}, Test samples: {len(x_test)}\")\n",
    "print(f\"Input dimension: {x_train.shape[1]}, Classes: {len(np.unique(y_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28 * 28, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 10),\n",
    "    torch.nn.Softmax(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NeuralNetClassifier(\n",
    "    nn_model,\n",
    "    max_epochs=15,\n",
    "    lr=0.1,\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "clf.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training score: {clf.score(x_train, y_train):.4}\")\n",
    "print(f\"Validation set score: {clf.score(x_test, y_test):.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_regression = torch.nn.Sequential(*nn_model[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Problem: Adversarial Example\n",
    "\n",
    "Find minimal L1 perturbation to misclassify a correctly classified image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageno = 10000\n",
    "image = mnist_train.data[imageno, :]\n",
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_prob = nn_regression.forward(x_train[imageno, :])\n",
    "sorted_labels = torch.argsort(ex_prob)\n",
    "right_label = sorted_labels[-1]\n",
    "wrong_label = sorted_labels[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Gurobi Model\n",
    "\n",
    "Single model reused for all formulations using `pred_constr.remove()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gurobi model\n",
    "m = gp.Model()\n",
    "m.Params.OutputFlag = 1\n",
    "m.Params.TimeLimit = 120\n",
    "\n",
    "delta = 5\n",
    "\n",
    "image = x_train[imageno, :].numpy()  # We need numpy converted image\n",
    "\n",
    "x = m.addMVar(image.shape, lb=0.0, ub=1.0, name=\"x\")\n",
    "y = m.addMVar(ex_prob.detach().numpy().shape, lb=-gp.GRB.INFINITY, name=\"y\")\n",
    "\n",
    "abs_diff = m.addMVar(image.shape, lb=0, ub=1, name=\"abs_diff\")\n",
    "\n",
    "m.setObjective(y[wrong_label] - y[right_label], gp.GRB.MAXIMIZE)\n",
    "\n",
    "# Bound on the distance to example in norm-1\n",
    "m.addConstr(abs_diff >= x - image)\n",
    "m.addConstr(abs_diff >= -x + image)\n",
    "m.addConstr(abs_diff.sum() <= delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Standard MIP ReLU (Global Optimality)\n",
    "\n",
    "- Uses piecewise-linear max formulation with binary variables\n",
    "- Solved to **global optimality**\n",
    "- Baseline for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictor with standard MIP formulation\n",
    "pred_constr = add_predictor_constr(m, nn_regression, x, y)\n",
    "\n",
    "pred_constr.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve to global optimality\n",
    "start = time.time()\n",
    "m.optimize()\n",
    "mip_time = time.time() - start\n",
    "\n",
    "mip_obj = m.ObjVal if m.Status == GRB.OPTIMAL else float(\"inf\")\n",
    "mip_gap = m.MIPGap if m.Status == GRB.OPTIMAL else 1.0\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\n",
    "    f\"MIP ReLU: Obj = {mip_obj:.4f}, Time = {mip_time:.2f}s, Gap = {mip_gap * 100:.2f}%\"\n",
    ")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sqrt ReLU (Local Optimality)\n",
    "\n",
    "- Uses `f(x) = (x + sqrt(x²))/2`, mathematically equivalent to ReLU\n",
    "- **Not smooth**: still non-differentiable at x=0 (since sqrt(x²) = |x|)\n",
    "- No binary variables; uses nonlinear barrier solver\n",
    "- Solved to **local optimality** (OptimalityTarget=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove MIP predictor and misclassification constraints\n",
    "pred_constr.remove()\n",
    "\n",
    "# Add sqrt ReLU formulation\n",
    "pred_constr = add_predictor_constr(m, nn_regression, x, y, relu_formulation=\"smooth\")\n",
    "\n",
    "pred_constr.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.update()\n",
    "print(\n",
    "    f\"Sqrt ReLU formulation: {m.NumVars} vars, {m.NumConstrs} constrs, {m.NumBinVars} binary vars\"\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "m.Params.OptimalityTarget = 1\n",
    "m.optimize()\n",
    "sqrt_time = time.time() - start\n",
    "\n",
    "sqrt_obj = m.ObjVal if m.Status in [GRB.OPTIMAL, GRB.USER_OBJ_LIMIT] else float(\"inf\")\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"Sqrt ReLU: Obj = {sqrt_obj:.4f}, Time = {sqrt_time:.2f}s\")\n",
    "print(f\"Gap to MIP: {(sqrt_obj / mip_obj - 1) * 100:+.1f}%\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Soft ReLU / Softplus (β=1.0, Local Optimality)\n",
    "\n",
    "- Uses `f(x) = log(1 + exp(βx))/β`\n",
    "- **Smooth approximation** of ReLU; differentiable everywhere\n",
    "- Lower β = smoother but less accurate approximation\n",
    "- Solved to **local optimality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous predictor and constraints\n",
    "pred_constr.remove()\n",
    "\n",
    "# Add soft ReLU with beta=1.0\n",
    "pred_constr = add_predictor_constr(\n",
    "    m, nn_regression, x, y, relu_formulation=\"soft\", soft_relu_beta=1.0\n",
    ")\n",
    "\n",
    "m.update()\n",
    "\n",
    "start = time.time()\n",
    "m.optimize()\n",
    "soft1_time = time.time() - start\n",
    "\n",
    "soft1_obj = (\n",
    "    m.ObjVal\n",
    "    if m.Status in [GRB.OPTIMAL, GRB.LOCALLY_OPTIMAL, GRB.USER_OBJ_LIMIT]\n",
    "    else float(\"inf\")\n",
    ")\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"Soft ReLU (β=1.0): Obj = {soft1_obj:.4f}, Time = {soft1_time:.2f}s\")\n",
    "print(f\"Gap to MIP: {(soft1_obj / mip_obj - 1) * 100:+.1f}%\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Soft ReLU / Softplus (β=5.0, Local Optimality)\n",
    "\n",
    "- Same as above but with **higher β** → closer to ReLU\n",
    "- Higher β = sharper transition, better approximation\n",
    "- Solved to **local optimality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous predictor and constraints\n",
    "pred_constr.remove()\n",
    "\n",
    "# Add soft ReLU with beta=5.0\n",
    "pred_constr = add_predictor_constr(\n",
    "    m, nn_regression, x, y, relu_formulation=\"soft\", soft_relu_beta=5.0\n",
    ")\n",
    "m.update()\n",
    "\n",
    "start = time.time()\n",
    "m.optimize()\n",
    "soft5_time = time.time() - start\n",
    "\n",
    "soft5_obj = m.ObjVal if m.Status in [GRB.OPTIMAL, GRB.USER_OBJ_LIMIT] else float(\"inf\")\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"Soft ReLU (β=5.0): Obj = {soft5_obj:.4f}, Time = {soft5_time:.2f}s\")\n",
    "print(f\"Gap to MIP: {(soft5_obj / mip_obj - 1) * 100:+.1f}%\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 75)\n",
    "print(f\"{'Formulation':<28} {'Objective':<12} {'Time (s)':<12} {'Gap to MIP'}\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'MIP ReLU (global)':<28} {mip_obj:<12.4f} {mip_time:<12.2f} {'baseline'}\")\n",
    "print(\n",
    "    f\"{'Sqrt ReLU (local)':<28} {sqrt_obj:<12.4f} {sqrt_time:<12.2f} {(sqrt_obj / mip_obj - 1) * 100:+.1f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"{'Soft ReLU β=1.0 (local)':<28} {soft1_obj:<12.4f} {soft1_time:<12.2f} {(soft1_obj / mip_obj - 1) * 100:+.1f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"{'Soft ReLU β=5.0 (local)':<28} {soft5_obj:<12.4f} {soft5_time:<12.2f} {(soft5_obj / mip_obj - 1) * 100:+.1f}%\"\n",
    ")\n",
    "print(\"=\" * 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Copyright © 2023-2026 Gurobi Optimization, LLC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "license": {
   "full_text": "# Copyright © 2026 Gurobi Optimization, LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================="
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
