{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU Formulation Comparison\n",
    "\n",
    "Compare different ReLU formulations: standard MIP (global optimal) vs. nonlinear formulations (local optimal).\n",
    "\n",
    "**Requirements:** torch, torchvision, skorch, matplotlib, gurobipy >= 12.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skorch import NeuralNetClassifier\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from gurobi_ml import add_predictor_constr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load digits dataset (8x8 images, 10 classes)\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X = X / 16.0  # Normalize to [0, 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "print(f\"Input dimension: {X.shape[1]}, Classes: {len(np.unique(y))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple neural network: 64 -> 32 -> 16 -> 10\n",
    "nn_model = nn.Sequential(\n",
    "    nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 16), nn.ReLU(), nn.Linear(16, 10)\n",
    ")\n",
    "\n",
    "# Train the network\n",
    "clf = NeuralNetClassifier(\n",
    "    nn_model,\n",
    "    max_epochs=20,\n",
    "    lr=0.01,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    verbose=0,\n",
    ")\n",
    "clf.fit(X_train.astype(np.float32), y_train.astype(np.int64))\n",
    "\n",
    "# Test accuracy\n",
    "train_acc = clf.score(X_train.astype(np.float32), y_train)\n",
    "test_acc = clf.score(X_test.astype(np.float32), y_test)\n",
    "print(f\"Train accuracy: {train_acc:.3f}, Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Problem: Adversarial Example\n",
    "\n",
    "Find minimal L1 perturbation to misclassify a correctly classified image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a correctly classified test example\n",
    "idx = 0\n",
    "x_input = X_test[idx]\n",
    "true_label = y_test[idx]\n",
    "predicted_label = clf.predict(x_input.reshape(1, -1).astype(np.float32))[0]\n",
    "print(f\"True label: {true_label}, Predicted: {predicted_label}\")\n",
    "\n",
    "# Verify it's correctly classified\n",
    "assert predicted_label == true_label, \"Example not correctly classified!\"\n",
    "print(f\"Input L1 norm: {np.sum(np.abs(x_input)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Gurobi Model\n",
    "\n",
    "Single model reused for all formulations using `pred_constr.remove()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gurobi model\n",
    "m = gp.Model()\n",
    "m.Params.OutputFlag = 1\n",
    "m.Params.TimeLimit = 120\n",
    "\n",
    "# Decision variables: perturbed input (stay in [0,1])\n",
    "x = m.addMVar(x_input.shape, lb=0, ub=1, name=\"x\")\n",
    "\n",
    "# Absolute value of perturbation using standard formulation\n",
    "delta = m.addMVar(x_input.shape, lb=-GRB.INFINITY, name=\"delta\")\n",
    "abs_delta = m.addMVar(x_input.shape, name=\"abs_delta\")\n",
    "m.addConstr(delta == x - x_input)\n",
    "m.addConstr(abs_delta >= delta)\n",
    "m.addConstr(abs_delta >= -delta)\n",
    "\n",
    "# Objective: minimize L1 norm of perturbation\n",
    "m.setObjective(abs_delta.sum(), GRB.MINIMIZE)\n",
    "m.update()\n",
    "\n",
    "print(f\"Model created with {m.NumVars} variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Standard MIP ReLU (Global Optimality)\n",
    "\n",
    "- Uses piecewise-linear max formulation with binary variables\n",
    "- Solved to **global optimality**\n",
    "- Baseline for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictor with standard MIP formulation\n",
    "pred_constr = add_predictor_constr(m, nn_model, x.reshape(1, -1))\n",
    "output = pred_constr.output\n",
    "\n",
    "# Misclassification constraints: output[0, i] >= output[0, true_label] + 0.01 for i != true_label\n",
    "misclass_constrs = []\n",
    "for i in range(10):\n",
    "    if i != true_label:\n",
    "        misclass_constrs.append(\n",
    "            m.addConstr(\n",
    "                output[0, i] >= output[0, true_label] + 0.01, name=f\"misclass_{i}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "m.update()\n",
    "print(\n",
    "    f\"MIP formulation: {m.NumVars} vars, {m.NumConstrs} constrs, {m.NumBinVars} binary vars\"\n",
    ")\n",
    "\n",
    "# Solve to global optimality\n",
    "start = time.time()\n",
    "m.optimize()\n",
    "mip_time = time.time() - start\n",
    "\n",
    "mip_obj = m.ObjVal if m.Status == GRB.OPTIMAL else float(\"inf\")\n",
    "mip_gap = m.MIPGap if m.Status == GRB.OPTIMAL else 1.0\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\n",
    "    f\"MIP ReLU: Obj = {mip_obj:.4f}, Time = {mip_time:.2f}s, Gap = {mip_gap * 100:.2f}%\"\n",
    ")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sqrt ReLU (Local Optimality)\n",
    "\n",
    "- Uses `f(x) = (x + sqrt(x²))/2`, mathematically equivalent to ReLU\n",
    "- **Not smooth**: still non-differentiable at x=0 (since sqrt(x²) = |x|)\n",
    "- No binary variables; uses nonlinear barrier solver\n",
    "- Solved to **local optimality** (OptimalityTarget=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove MIP predictor and misclassification constraints\n",
    "pred_constr.remove()\n",
    "for c in misclass_constrs:\n",
    "    m.remove(c)\n",
    "\n",
    "# Add sqrt ReLU formulation\n",
    "m.Params.NonConvex = 2\n",
    "m.Params.OptimalityTarget = 1  # Local optimality\n",
    "pred_constr = add_predictor_constr(\n",
    "    m, nn_model, x.reshape(1, -1), relu_formulation=\"smooth\"\n",
    ")\n",
    "output = pred_constr.output\n",
    "\n",
    "# Re-add misclassification constraints\n",
    "misclass_constrs = []\n",
    "for i in range(10):\n",
    "    if i != true_label:\n",
    "        misclass_constrs.append(\n",
    "            m.addConstr(\n",
    "                output[0, i] >= output[0, true_label] + 0.01, name=f\"misclass_{i}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "m.update()\n",
    "print(\n",
    "    f\"Sqrt ReLU formulation: {m.NumVars} vars, {m.NumConstrs} constrs, {m.NumBinVars} binary vars\"\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "m.optimize()\n",
    "sqrt_time = time.time() - start\n",
    "\n",
    "sqrt_obj = m.ObjVal if m.Status in [GRB.OPTIMAL, GRB.USER_OBJ_LIMIT] else float(\"inf\")\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"Sqrt ReLU: Obj = {sqrt_obj:.4f}, Time = {sqrt_time:.2f}s\")\n",
    "print(f\"Gap to MIP: {(sqrt_obj / mip_obj - 1) * 100:+.1f}%\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Soft ReLU / Softplus (β=1.0, Local Optimality)\n",
    "\n",
    "- Uses `f(x) = log(1 + exp(βx))/β`\n",
    "- **Smooth approximation** of ReLU; differentiable everywhere\n",
    "- Lower β = smoother but less accurate approximation\n",
    "- Solved to **local optimality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous predictor and constraints\n",
    "pred_constr.remove()\n",
    "for c in misclass_constrs:\n",
    "    m.remove(c)\n",
    "\n",
    "# Add soft ReLU with beta=1.0\n",
    "pred_constr = add_predictor_constr(\n",
    "    m, nn_model, x.reshape(1, -1), relu_formulation=\"soft\", soft_relu_beta=1.0\n",
    ")\n",
    "output = pred_constr.output\n",
    "\n",
    "misclass_constrs = []\n",
    "for i in range(10):\n",
    "    if i != true_label:\n",
    "        misclass_constrs.append(\n",
    "            m.addConstr(\n",
    "                output[0, i] >= output[0, true_label] + 0.01, name=f\"misclass_{i}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "m.update()\n",
    "\n",
    "start = time.time()\n",
    "m.optimize()\n",
    "soft1_time = time.time() - start\n",
    "\n",
    "soft1_obj = m.ObjVal if m.Status in [GRB.OPTIMAL, GRB.USER_OBJ_LIMIT] else float(\"inf\")\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"Soft ReLU (β=1.0): Obj = {soft1_obj:.4f}, Time = {soft1_time:.2f}s\")\n",
    "print(f\"Gap to MIP: {(soft1_obj / mip_obj - 1) * 100:+.1f}%\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Soft ReLU / Softplus (β=5.0, Local Optimality)\n",
    "\n",
    "- Same as above but with **higher β** → closer to ReLU\n",
    "- Higher β = sharper transition, better approximation\n",
    "- Solved to **local optimality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous predictor and constraints\n",
    "pred_constr.remove()\n",
    "for c in misclass_constrs:\n",
    "    m.remove(c)\n",
    "\n",
    "# Add soft ReLU with beta=5.0\n",
    "pred_constr = add_predictor_constr(\n",
    "    m, nn_model, x.reshape(1, -1), relu_formulation=\"soft\", soft_relu_beta=5.0\n",
    ")\n",
    "output = pred_constr.output\n",
    "\n",
    "misclass_constrs = []\n",
    "for i in range(10):\n",
    "    if i != true_label:\n",
    "        misclass_constrs.append(\n",
    "            m.addConstr(\n",
    "                output[0, i] >= output[0, true_label] + 0.01, name=f\"misclass_{i}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "m.update()\n",
    "\n",
    "start = time.time()\n",
    "m.optimize()\n",
    "soft5_time = time.time() - start\n",
    "\n",
    "soft5_obj = m.ObjVal if m.Status in [GRB.OPTIMAL, GRB.USER_OBJ_LIMIT] else float(\"inf\")\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"Soft ReLU (β=5.0): Obj = {soft5_obj:.4f}, Time = {soft5_time:.2f}s\")\n",
    "print(f\"Gap to MIP: {(soft5_obj / mip_obj - 1) * 100:+.1f}%\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 75)\n",
    "print(f\"{'Formulation':<28} {'Objective':<12} {'Time (s)':<12} {'Gap to MIP'}\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'MIP ReLU (global)':<28} {mip_obj:<12.4f} {mip_time:<12.2f} {'baseline'}\")\n",
    "print(\n",
    "    f\"{'Sqrt ReLU (local)':<28} {sqrt_obj:<12.4f} {sqrt_time:<12.2f} {(sqrt_obj / mip_obj - 1) * 100:+.1f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"{'Soft ReLU β=1.0 (local)':<28} {soft1_obj:<12.4f} {soft1_time:<12.2f} {(soft1_obj / mip_obj - 1) * 100:+.1f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"{'Soft ReLU β=5.0 (local)':<28} {soft5_obj:<12.4f} {soft5_time:<12.2f} {(soft5_obj / mip_obj - 1) * 100:+.1f}%\"\n",
    ")\n",
    "print(\"=\" * 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Copyright © 2023-2026 Gurobi Optimization, LLC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "license": {
   "full_text": "# Copyright © 2026 Gurobi Optimization, LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================="
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
