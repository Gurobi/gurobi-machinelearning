{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a00ac5",
   "metadata": {},
   "source": [
    "# Price Optimization\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Note\n",
    "\n",
    "This example is adapted from the example in Gurobi's modeling examples [How Much\n",
    "Is Too Much? Avocado Pricing and Supply Using Mathematical\n",
    "Optimization](https://github.com/Gurobi/modeling-examples/tree/master/price_optimization).\n",
    "\n",
    "The main difference is that it uses `Scikit-learn` for the regression model and\n",
    "Gurobi Machine Learning to embed the regression in a Gurobi model.\n",
    "\n",
    "But it also differs in that it uses Matrix variables and that the interactive\n",
    "part of the notebook is skipped. Please refer to the original example for this.\n",
    "\n",
    "This example illustrates in particular how to use categorical variables in a\n",
    "regression.\n",
    "\n",
    "If you are already familiar with the example from the other notebook, you can\n",
    "jump directly to [building the regression model](#Part-II:-Predict-the-Sales)\n",
    "and then to [formulating the optimization\n",
    "problem](#Part-III:-Optimize-for-Price-and-Supply-of-Avocados).\n",
    "</div>\n",
    "\n",
    "A [Food Network\n",
    "article](https://www.foodnetwork.com/fn-dish/news/2018/3/avocado-unseats-banana-as-america-s-top-fruit-import-by-value)\n",
    "from March 2017 declared, \"Avocado unseats banana as America's top fruit\n",
    "import.\" This declaration is incomplete and debatable for reasons other than\n",
    "whether  avocado is a fruit. Avocados are expensive.\n",
    "\n",
    "As a supplier, setting an appropriate avocado price requires a delicate\n",
    "trade-off. Set it too high and you lose customers. Set it too low, and you won't\n",
    "make a profit. Equipped with good data, the avocado pricing and supply problem\n",
    "is *ripe* with opportunities for demonstrating the power of optimization and\n",
    "data science.\n",
    "\n",
    "They say when life gives you avocados, make guacamole. Just like the perfect\n",
    "guacamole needs the right blend of onion, lemon and spices, finding an optimal\n",
    "avocado price needs the right blend of descriptive, predictive and prescriptive\n",
    "analytics.\n",
    "\n",
    "|<img\n",
    "src=\"https://github.com/Gurobi/modeling-examples/blob/master/price_optimization/avocado_image_grocery.jpeg?raw=1\"\n",
    "width=\"500\" align=\"center\">| |:--:| | <b>Avocados: a quintessential corner of a\n",
    "grocery store. Image Credits: [New York\n",
    "Post](https://nypost.com/2022/02/15/us-will-halt-mexico-avocado-imports-as-long-as-necessary/)\n",
    "</b>|\n",
    "\n",
    "\n",
    "**Goal**: Develop a data science pipeline for pricing and distribution of\n",
    "avocados to maximize revenue.\n",
    "\n",
    "This notebook walks through a decision-making pipeline that culminates in a\n",
    "mathematical optimization model. There are three stages:\n",
    "\n",
    "- First, understand the dataset and infer the relationships between categories\n",
    "  such as the sales, price, region, and seasonal trends.\n",
    "- Second, build a prediction model that predicts the demand for avocados as a\n",
    "  function of price, region, year and the seasonality.\n",
    "- Third, design an optimization problem that sets the optimal price and supply\n",
    "  quantity to maximize the net revenue while incorporating costs for wastage and\n",
    "  transportation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ed7e0",
   "metadata": {},
   "source": [
    "## Load the Packages and the Datasets\n",
    "\n",
    "We use real sales data provided by the [Hass Avocado\n",
    "Board](https://hassavocadoboard.com/) (HAB), whose aim is to \"make avocados\n",
    "Americaâ€™s most popular fruit\". This dataset contains consolidated information on\n",
    "several years' worth of market prices and sales of avocados.\n",
    "\n",
    "We will now load the following packages for analyzing and visualizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff1bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e41c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobi_ml import add_predictor_constr\n",
    "import gurobipy_pandas as gppd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408e66ab",
   "metadata": {},
   "source": [
    "The dataset from HAB contains sales data for the years 2019-2022. This data is\n",
    "augmented by a previous download from HAB available on\n",
    "[Kaggle](https://www.kaggle.com/datasets/timmate/avocado-prices-2020) with sales\n",
    "for the years 2015-2018.\n",
    "\n",
    "Each row in the dataset is the weekly number of avocados sold and the weekly\n",
    "average price of an avocado categorized by region and type of avocado. There are\n",
    "two types of avocados: conventional and organic. In this notebook, we will only\n",
    "consider the conventional avocados. There are eight large regions, namely the\n",
    "Great Lakes, Midsouth, North East, Northern New England, South Central, South\n",
    "East, West and Plains.\n",
    "\n",
    "Now, load the data and store into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://raw.githubusercontent.com/Gurobi/modeling-examples/master/price_optimization/\"\n",
    "avocado = pd.read_csv(\n",
    "    data_url + \"HABdata_2019_2022.csv\"\n",
    ")  # dataset downloaded directly from HAB\n",
    "avocado_old = pd.read_csv(\n",
    "    data_url + \"kaggledata_till2018.csv\"\n",
    ")  # dataset downloaded from Kaggle\n",
    "avocado = pd.concat([avocado, avocado_old])\n",
    "avocado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c596d",
   "metadata": {},
   "source": [
    "## Prepare the Dataset\n",
    "\n",
    "We will now prepare the data for making sales predictions. Add new columns to\n",
    "the dataframe for the year and seasonality. Let each year from 2015 through 2022\n",
    "be given an index from 0 through 7 in the increasing order of the year. We will\n",
    "define the peak season to be the months of February through July. These months\n",
    "are set based on visual inspection of the trends, but you can try setting other\n",
    "months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb54fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the index for each year from 2015 through 2022\n",
    "avocado[\"date\"] = pd.to_datetime(avocado[\"date\"])\n",
    "avocado[\"year\"] = pd.DatetimeIndex(avocado[\"date\"]).year\n",
    "avocado[\"year_index\"] = avocado[\"year\"] - 2015\n",
    "avocado = avocado.sort_values(by=\"date\")\n",
    "\n",
    "# Define the peak season\n",
    "avocado[\"month\"] = pd.DatetimeIndex(avocado[\"date\"]).month\n",
    "peak_months = range(2, 8)  # <--------- Set the months for the \"peak season\"\n",
    "\n",
    "\n",
    "def peak_season(row):\n",
    "    return 1 if int(row[\"month\"]) in peak_months else 0\n",
    "\n",
    "\n",
    "avocado[\"peak\"] = avocado.apply(lambda row: peak_season(row), axis=1)\n",
    "\n",
    "# Scale the number of avocados to millions\n",
    "avocado[\"units_sold\"] = avocado[\"units_sold\"] / 1000000\n",
    "\n",
    "# Select only conventional avocados\n",
    "avocado = avocado[avocado[\"type\"] == \"Conventional\"]\n",
    "\n",
    "avocado = avocado[\n",
    "    [\"date\", \"units_sold\", \"price\", \"region\", \"year\", \"month\", \"year_index\", \"peak\"]\n",
    "].reset_index(drop=True)\n",
    "\n",
    "avocado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb1aefc",
   "metadata": {},
   "source": [
    "## Part 1: Observe Trends in the Data\n",
    "\n",
    "Now, we will infer sales trends in time and seasonality. For simplicity, let's\n",
    "proceed with data from the United States as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec2ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Total_US = avocado[avocado[\"region\"] == \"Total_US\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c0ac5",
   "metadata": {},
   "source": [
    "### Sales Over the Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f7336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "mean = df_Total_US.groupby(\"year\")[\"units_sold\"].mean()\n",
    "std = df_Total_US.groupby(\"year\")[\"units_sold\"].std()\n",
    "axes.errorbar(mean.index, mean, xerr=0.5, yerr=2 * std, linestyle=\"\")\n",
    "axes.set_ylabel(\"Units Sold (millions)\")\n",
    "axes.set_xlabel(\"Year\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a9a13d",
   "metadata": {},
   "source": [
    "We can see that the sales generally increased over the years, albeit marginally.\n",
    "The dip in 2019 is the effect of the well-documented [2019 avocado\n",
    "shortage](https://abc7news.com/avocado-shortage-season-prices/5389855/) that led\n",
    "to avocados [nearly doubling in\n",
    "price.](https://abc7news.com/avocado-shortage-season-prices/5389855/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa3122e",
   "metadata": {},
   "source": [
    "### Seasonality\n",
    "\n",
    "We will now see the sales trends within a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9854f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "mean = df_Total_US.groupby(\"month\")[\"units_sold\"].mean()\n",
    "std = df_Total_US.groupby(\"month\")[\"units_sold\"].std()\n",
    "\n",
    "axes.errorbar(mean.index, mean, xerr=0.5, yerr=2 * std, linestyle=\"\")\n",
    "axes.set_ylabel(\"Units Sold (millions)\")\n",
    "axes.set_xlabel(\"Month\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.xlabel(\"Month\")\n",
    "axes.set_xticks(range(1, 13))\n",
    "plt.ylabel(\"Units sold (millions)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ab2c0",
   "metadata": {},
   "source": [
    "We see a Super Bowl peak in February and a Cinco de Mayo peak in May."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae0d4dd",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "\n",
    "Now, we will see how the variables are correlated with each other. The end goal\n",
    "is to predict sales given the price of an avocado, year and seasonality (peak or\n",
    "not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f9eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(15, 5))\n",
    "sns.heatmap(\n",
    "    df_Total_US[[\"units_sold\", \"price\", \"year\", \"peak\"]].corr(),\n",
    "    annot=True,\n",
    "    center=0,\n",
    "    ax=axes,\n",
    ")\n",
    "\n",
    "axes.set_title(\"Correlations for conventional avocados\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6451ab3",
   "metadata": {},
   "source": [
    "As expected, the sales quantity has a negative correlation with the price per\n",
    "avocado. The sales quantity has a positive correlation with the year and season\n",
    "being a peak season."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91caa2",
   "metadata": {},
   "source": [
    "### Regions\n",
    "\n",
    "Finally, we will see how the sales differ among the different regions. This will\n",
    "determine the number of avocados that we want to supply to each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "regions = [\n",
    "    \"Great_Lakes\",\n",
    "    \"Midsouth\",\n",
    "    \"Northeast\",\n",
    "    \"Northern_New_England\",\n",
    "    \"SouthCentral\",\n",
    "    \"Southeast\",\n",
    "    \"West\",\n",
    "    \"Plains\",\n",
    "]\n",
    "df = avocado[avocado.region.isin(regions)]\n",
    "\n",
    "mean = df.groupby(\"region\")[\"units_sold\"].mean()\n",
    "std = df.groupby(\"region\")[\"units_sold\"].std()\n",
    "\n",
    "axes.errorbar(range(len(mean)), mean, xerr=0.5, yerr=2 * std, linestyle=\"\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.xlabel(\"Region\")\n",
    "plt.xticks(range(len(mean)), pd.DataFrame(mean)[\"units_sold\"].index, rotation=20)\n",
    "plt.ylabel(\"Units sold (millions)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2e58e",
   "metadata": {},
   "source": [
    "Clearly, west-coasters love avocados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5186fd3e",
   "metadata": {},
   "source": [
    "## Part II: Predict the Sales\n",
    "\n",
    "The trends observed in Part I motivate us to construct a prediction model for\n",
    "sales using the independent variables- price, year, region and seasonality.\n",
    "Henceforth, the sales quantity will be referred to as the *predicted demand*.\n",
    "\n",
    "Let us now construct a linear regressor for the demand. Note that the region is\n",
    "a categorical variable, to encode it for the regression we will use the\n",
    "`OneHotEncoder` of `Scikit-learn`.\n",
    "\n",
    "Because Gurobi Machine Learning doesn't support this column transformation at\n",
    "this point, we need to apply the transform to the data directly **before**\n",
    "applying the regression. We will then show below how to use it to build the\n",
    "model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa91a90",
   "metadata": {},
   "source": [
    "We prepare the data using `OneHotEncoder` and `make_column_transformer`. We want\n",
    "to transform the region feature using the encoder while the other features\n",
    "should be unchanged.\n",
    "\n",
    "Furthermore, we store in X the transformed data and in y the target value\n",
    "units_sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "feat_transform = make_column_transformer(\n",
    "    (OneHotEncoder(drop=\"first\"), [\"region\"]),\n",
    "    (StandardScaler(), [\"price\", \"year_index\"]),\n",
    "    (\"passthrough\", [\"peak\"]),\n",
    "    verbose_feature_names_out=False,\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "X = df[[\"region\", \"price\", \"year_index\", \"peak\"]]\n",
    "y = df[\"units_sold\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb9ee7",
   "metadata": {},
   "source": [
    "To validate the regression model, we will randomly split the dataset into $80\\%$\n",
    "training and $20\\%$ testing data and learn the weights using `Scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.8, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071154e3",
   "metadata": {},
   "source": [
    "Finally, create the regression model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16294bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.base import clone\n",
    "from time import time\n",
    "regressions = {\"Linear Regression\": {\"regressor\":LinearRegression()},\n",
    "               \"MLP Regression\": {\"regressor\": MLPRegressor([10*2])},\n",
    "               \"Decision Tree\": {\"regressor\": DecisionTreeRegressor()},\n",
    "               \"Random Forest\": {\"regressor\": RandomForestRegressor()},\n",
    "               \"Gradient Boosting\":\n",
    "               {\"regressor\" : GradientBoostingRegressor()}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6cb443",
   "metadata": {},
   "outputs": [],
   "source": [
    "for regression, data in regressions.items():\n",
    "    lin_reg = make_pipeline(feat_transform,\n",
    "                            data[\"regressor\"])\n",
    "    train_start = time()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    data[\"train_time\"] = time() - train_start\n",
    "    data[\"pipeline\"] = lin_reg\n",
    "\n",
    "    # Get R^2 from test data\n",
    "    y_pred = lin_reg.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    data[\"R2\"] = r2\n",
    "    print(f\"The R^2 value in the test set is {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressions_poly = {}\n",
    "for regression, data in regressions.items():\n",
    "    data = {\"regressor\": clone(data[\"regressor\"])}\n",
    "    lin_reg = make_pipeline(feat_transform, PolynomialFeatures(),\n",
    "                            data[\"regressor\"])\n",
    "    train_start = time()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    data[\"train_time\"] = time() - train_start\n",
    "    data[\"pipeline\"] = lin_reg\n",
    "\n",
    "    # Get R^2 from test data\n",
    "    y_pred = lin_reg.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    data[\"R2\"] = r2\n",
    "    regressions_poly[f\"{regression} with polynomial features\"] = data\n",
    "\n",
    "    print(f\"The R^2 value in the test set is {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d67bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressions |= regressions_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291d28d",
   "metadata": {},
   "source": [
    "We can observe a good $R^2$ value in the test set. We will now train the fit the\n",
    "weights to the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b956503",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.fit(X, y)\n",
    "\n",
    "y_pred_full = lin_reg.predict(X)\n",
    "print(f\"The R^2 value in the full dataset is {r2_score(y, y_pred_full)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f48f80",
   "metadata": {},
   "source": [
    "## Part III: Optimize for Price and Supply of Avocados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Sets and parameters\n",
    "R = len(regions)  # set of all regions\n",
    "\n",
    "B = 30  # total amount ot avocado supply\n",
    "\n",
    "peak_or_not = 1  # 1 if it is the peak season; 1 if isn't\n",
    "year = 2020\n",
    "\n",
    "c_waste = 0.1  # the cost ($) of wasting an avocado\n",
    "# the cost of transporting an avocado\n",
    "c_transport = pd.Series(\n",
    "    {\n",
    "        \"Great_Lakes\": 0.3,\n",
    "        \"Midsouth\": 0.1,\n",
    "        \"Northeast\": 0.4,\n",
    "        \"Northern_New_England\": 0.5,\n",
    "        \"SouthCentral\": 0.3,\n",
    "        \"Southeast\": 0.2,\n",
    "        \"West\": 0.2,\n",
    "        \"Plains\": 0.2,\n",
    "    }, name='transport_cost'\n",
    ")\n",
    "\n",
    "c_transport = c_transport.loc[regions]\n",
    "# the cost of transporting an avocado\n",
    "\n",
    "# Get the lower and upper bounds from the dataset for the price and the number of products to be stocked\n",
    "a_min = 0  # minimum avocado price in each region\n",
    "a_max = 2  # maximum avocado price in each region\n",
    "\n",
    "data = pd.concat([c_transport,\n",
    "                  df.groupby(\"region\")[\"units_sold\"].min().rename('min_delivery'),\n",
    "                  df.groupby(\"region\")[\"units_sold\"].max().rename('max_delivery')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de910ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gp.Model(\"Avocado_Price_Allocation\")\n",
    "\n",
    "x = gppd.add_vars(m, data, name=\"x\", lb='min_delivery', ub='max_delivery')\n",
    "s = gppd.add_vars(m, data, name=\"s\") # predicted amount of sales in each region for the given price).\n",
    "w = gppd.add_vars(m, data, name=\"w\") # excess wasteage in each region).\n",
    "d = gppd.add_vars(m, data, lb=-gp.GRB.INFINITY, name=\"demand\") # Add variables for the regression\n",
    "p = gppd.add_vars(m, data, name=\"price\", lb=a_min, ub=a_max)\n",
    "m.update()\n",
    "\n",
    "m.setObjective((p * s).sum() - c_waste * w.sum() - (c_transport * x).sum())\n",
    "m.ModelSense = GRB.MAXIMIZE\n",
    "\n",
    "m.addConstr(x.sum() == B)\n",
    "m.update()\n",
    "\n",
    "gppd.add_constrs(m, s, gp.GRB.LESS_EQUAL, x)\n",
    "gppd.add_constrs(m, s, gp.GRB.LESS_EQUAL, d)\n",
    "m.update()\n",
    "\n",
    "gppd.add_constrs(m, w, gp.GRB.EQUAL, x - s)\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d903bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = pd.DataFrame(\n",
    "    data={\n",
    "        \"year_index\": year - 2015,\n",
    "        \"peak\": peak_or_not,\n",
    "        \"region\": regions,\n",
    "    },\n",
    "    index=regions\n",
    ")\n",
    "feats = pd.concat([feats, p], axis=1)[[\"region\", \"price\", \"year_index\", \"peak\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6452a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for regression, data in regressions.items():\n",
    "    pred_constr = add_predictor_constr(m, data[\"pipeline\"], feats, d)\n",
    "\n",
    "    pred_constr.print_stats()\n",
    "\n",
    "    m.Params.NonConvex = 2\n",
    "    m.write(f\"{regression}.rlp\")\n",
    "    try:\n",
    "        start = time()\n",
    "        m.optimize()\n",
    "        data[\"opt_time\"] = time() - start\n",
    "    except:\n",
    "        data[\"opt_time\"] = float('nan')\n",
    "        break\n",
    "        pass\n",
    "    pred_constr.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = !ls -l *.rlp\n",
    "\n",
    "sizes = {line[46:-4]: line.split()[4] for line in files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6641af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sizes.items():\n",
    "    regressions[key][\"file_size\"] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2496fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressions[\"Linear Regression\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(regressions, orient='index').drop([\"regressor\", \"pipeline\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3474030",
   "metadata": {},
   "source": [
    "The solver solved the optimization problem in less than a second. Let us now\n",
    "analyze the optimal solution by storing it in a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame(index=regions)\n",
    "\n",
    "solution[\"Price\"] = p.gppd.X\n",
    "solution[\"Allocated\"] = x.gppd.X\n",
    "solution[\"Sold\"] = s.gppd.X\n",
    "solution[\"Wasted\"] = w.gppd.X\n",
    "solution[\"Pred_demand\"] = d.gppd.X\n",
    "\n",
    "opt_revenue = m.ObjVal\n",
    "print(\"\\n The optimal net revenue: $%f million\" % opt_revenue)\n",
    "solution.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34279917",
   "metadata": {},
   "source": [
    "We can also check the error in the estimate of the Gurobi solution for the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353149d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Maximum error in approximating the regression {:.6}\".format(\n",
    "        np.max(pred_constr.get_error())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e7114c",
   "metadata": {},
   "source": [
    "And the computed features of the regression model in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d3599",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_constr.input_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bb9dfb",
   "metadata": {},
   "source": [
    "Let us now visualize a scatter plot between the price and the number of avocados\n",
    "sold (in millions) for the eight regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1590957",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "plot_sol = sns.scatterplot(data=solution, x=\"Price\", y=\"Sold\", hue=solution.index, s=100)\n",
    "plot_waste = sns.scatterplot(\n",
    "    data=solution, x=\"Price\", y=\"Wasted\", marker=\"x\", hue=solution.index, s=100, legend=False\n",
    ")\n",
    "\n",
    "plot_sol.legend(loc=\"center left\", bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plot_waste.legend(loc=\"center left\", bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.ylim(0, 5)\n",
    "plt.xlim(1, 2.2)\n",
    "ax.set_xlabel(\"Price per avocado ($)\")\n",
    "ax.set_ylabel(\"Number of avocados sold (millions)\")\n",
    "plt.show()\n",
    "print(\n",
    "    \"The circles represent sales quantity and the cross markers represent the wasted quantity.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b4a665",
   "metadata": {},
   "source": [
    "We have shown how to model the price and supply optimization problem with Gurobi\n",
    "Machine Learning. In the [Gurobi modeling examples\n",
    "notebook](https://github.com/Gurobi/modeling-examples/tree/master/price_optimization)\n",
    "more analysis of the solutions this model can give is done interactively. Be\n",
    "sure to take look at it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fbba6",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "Copyright Â© 2022 Gurobi Optimization, LLC"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb///ipynb,myst///md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "license": {
   "full_text": "# Copyright Â© 2022 Gurobi Optimization, LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================="
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
