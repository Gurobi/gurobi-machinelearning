{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eba6234",
   "metadata": {},
   "source": [
    "# Student Enrollment\n",
    "\n",
    "In this example, we show how to reproduce the model of student enrollment from\n",
    "<cite data-cite=\"JANOS\">Bergman et.al. (2020)</cite> with Gurobi Machine\n",
    "Learning.\n",
    "\n",
    "This model was developed in the context of the development of\n",
    "[Janos](https://github.com/INFORMSJoC/2020.1023), a toolkit similar to Gurobi\n",
    "Machine Learning to integrate ML models and Mathematical Optimization.\n",
    "\n",
    "This example illustrates in particular how to use the logistic regression and\n",
    "tune the piecewise-linear approximation of the logistic function.\n",
    "\n",
    "We also show how to deal with fixed features in the optimization model using\n",
    "pandas data frames.\n",
    "\n",
    "In this model, data of students admissions in a college is used to predict the\n",
    "probability that a student enrolls to the college.\n",
    "\n",
    "The data has 3 features: the SAT and GPA scores of each student, and the\n",
    "scholarship (or merit) that was offered to each student. Finally, it is known if\n",
    "each student decided to join the college or not.\n",
    "\n",
    "Based on this data a logistic regression is trained to predict the probability\n",
    "that a student joins the college.\n",
    "\n",
    "Using this regression model, <cite data-cite=\"JANOS\">Bergman et.al.\n",
    "(2020)</cite> proposes the following student enrollment problem. The Admission\n",
    "Office has data for SAT and GPA scores of the admitted students for the incoming\n",
    "class, and they would want to offer scholarships to students with the goal of\n",
    "maximizing the expected number of students that enroll in the college. There is\n",
    "a total of $n$ students that are admitted. The maximal budget for the sum of all\n",
    "scholarships offered is $0.2 n \\, \\text{K\\$}$ and each student can be offered a\n",
    "scholarship of at most $2.5 \\, \\text{K\\$}$.\n",
    "\n",
    "This problem can be expressed as a mathematical optimization problem as follows.\n",
    "Two vectors of decision variables $x$ and $y$ of dimension $n$ are used to model\n",
    "respectively the scholarship offered to each student in $\\text{K\\$}$ and the\n",
    "probability that they join. Denoting by $g$ the prediction function for the\n",
    "probability of the logistic regression we then have for each student $i$:\n",
    "\n",
    "$$ y_i = g(x_i, SAT_i, GPA_i), $$\n",
    "\n",
    "with $SAT_i$ and $GPA_i$ the (known) SAT and GPA score of each student.\n",
    "\n",
    "The objective is to maximize the sum of the $y$ variables and the budget\n",
    "constraint imposes that the sum of the variables $x$ is less or equal to $0.2n$.\n",
    "Also, each variable $x_i$ is between 0 and 2.5.\n",
    "\n",
    "The full model then reads:\n",
    "\n",
    "$$ \\begin{aligned} &\\max \\sum_{i=1}^n y_i \\\\\n",
    "&\\text{subject to:}\\\\\n",
    "&\\sum_{i=1}^n x_i \\le 0.2*n,\\\\\n",
    "&y_i = g(x_i, SAT_i, GPA_i) & & i = 1, \\ldots, n,\\\\\n",
    "& 0 \\le x \\le 2.5. \\end{aligned} $$\n",
    "\n",
    "Note that in this example differently to <cite data-cite=\"JANOS\">Bergman et.al.\n",
    "(2020)</cite> we scale the features for the regression. Also, to fit in Gurobi's\n",
    "limited size license we only consider the problem where $n=250$.\n",
    "\n",
    "We note also that the model may differ from the objectives of Admission Offices\n",
    "and don't encourage its use in real life. The example is for illustration\n",
    "purposes only.\n",
    "\n",
    "## Importing packages and retrieving the data\n",
    "\n",
    "We import the necessary packages. Besides the usual (`numpy`, `gurobipy`,\n",
    "`pandas`), for this we will use Scikit-learn's Pipeline, StandardScaler and\n",
    "LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9961b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobi_ml import add_predictor_constr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a96d64",
   "metadata": {},
   "source": [
    "We now retrieve the historical data used to build the regression from Janos\n",
    "repository.\n",
    "\n",
    "The features we use for the regression are `\"merit\"` (scholarship), `\"SAT\"` and\n",
    "`\"GPA\"` and the target is `\"enroll\"`. We store those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24154c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for retrieving data\n",
    "janos_data_url = \"https://raw.githubusercontent.com/INFORMSJoC/2020.1023/master/data/\"\n",
    "historical_data = pd.read_csv(\n",
    "    janos_data_url + \"college_student_enroll-s1-1.csv\", index_col=0\n",
    ")\n",
    "\n",
    "# classify our features between the ones that are fixed and the ones that will be\n",
    "# part of the optimization problem\n",
    "features = [\"merit\", \"SAT\", \"GPA\"]\n",
    "target = \"enroll\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a87740e",
   "metadata": {},
   "source": [
    "## Fit the logistic regression\n",
    "\n",
    "For the regression, we use a pipeline with a standard scaler and a logistic\n",
    "regression. We build it using the `make_pipeline` from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run our regression\n",
    "regression = LogisticRegression(random_state=1)\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(random_state=1))\n",
    "pipe.fit(X=historical_data.loc[:, features], y=historical_data.loc[:, target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4236c46e",
   "metadata": {},
   "source": [
    "### Optimization Model\n",
    "\n",
    "We now turn to building the mathematical optimization model for Gurobi.\n",
    "\n",
    "First, retrieve the data for the new students. We won't use all the data there,\n",
    "we randomly pick 250 students from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve new data used to build the optimization problem\n",
    "studentsdata = pd.read_csv(janos_data_url + \"college_applications6000.csv\", index_col=0)\n",
    "\n",
    "nstudents = 250\n",
    "\n",
    "# Select randomly nstudents in the data\n",
    "studentsdata = studentsdata.sample(nstudents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec5dd04",
   "metadata": {},
   "source": [
    "A non-trivial part of the model is the decision variables that we need for using\n",
    "Gurobi Machine Learning.\n",
    "\n",
    "In the mathematical formulation above, we only had two vectors of variables `x`\n",
    "and `y`. Then each student had associated its score $SAT_i$ and $GPA_i$ that\n",
    "were fixed parameters in the optimization. For the Gurobi model, we need to\n",
    "create a matrix of variables that also includes the values of $SAT$ and $GPA$ of\n",
    "each student. We will fix those variables by giving them the same lower bound\n",
    "and upper bound.\n",
    "\n",
    "Therefore, we need to build 2 matrices of variables, one for each set of bounds,\n",
    "and we need to make sure that they are in the same order as the regression model\n",
    "would expect.\n",
    "\n",
    "To do so, we use `pandas` data frames to construct those lower and upper bounds.\n",
    "\n",
    "To construct the lower bounds, we first make a copy of `studentsdata` and then\n",
    "add the `\"merit\"` column with a value of $0$. We then do the same for the upper\n",
    "bound, except that the value for `\"merit\"`is $2.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct lower bounds data frame\n",
    "feat_lb = studentsdata.copy()\n",
    "feat_lb.loc[:, \"merit\"] = 0\n",
    "\n",
    "# Construct upper bounds data frame\n",
    "feat_ub = studentsdata.copy()\n",
    "feat_ub.loc[:, \"merit\"] = 2.5\n",
    "\n",
    "# Make sure the columns are ordered in the same way as for the regression model.\n",
    "feat_lb = feat_lb[features]\n",
    "feat_ub = feat_ub[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861392fc",
   "metadata": {},
   "source": [
    "We can now create the variables for our model: `feature_vars` is initialized\n",
    "using the data frames we just created (be careful that they have to be converted\n",
    "to `numpy` arrays).\n",
    "\n",
    "For the rest of the model, we want to recover from the `feature_vars` matrix,\n",
    "the column corresponding to merit. With `pandas`, we can use the `get_indexer`\n",
    "function to recover the index of this column in our `MVar` matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134985f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with classical part of the model\n",
    "m = gp.Model()\n",
    "\n",
    "feature_vars = m.addMVar(\n",
    "    feat_lb.shape, lb=feat_lb.to_numpy(), ub=feat_ub.to_numpy(), name=\"feats\"\n",
    ")\n",
    "y = m.addMVar(nstudents, name=\"y\")\n",
    "\n",
    "x = feature_vars[:, feat_lb.columns.get_indexer([\"merit\"])][:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a83662",
   "metadata": {},
   "source": [
    "We add the objective and the budget constraint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.setObjective(y.sum(), gp.GRB.MAXIMIZE)\n",
    "\n",
    "m.addConstr(x.sum() <= 0.2 * nstudents)\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0719c",
   "metadata": {},
   "source": [
    "Finally, we insert the constraints from the regression. In this model we want to\n",
    "have use the probability estimate of a student joining the college, so we choose\n",
    "the parameter `output_type` to be `\"probability_1\"`. Note that due to the shapes\n",
    "of the `feature_vars` matrix and `y`, this will insert one regression constraint\n",
    "for each student.\n",
    "\n",
    "With the `print_stats` function we display what was added to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_constr = add_predictor_constr(\n",
    "    m, pipe, feature_vars, y, output_type=\"probability_1\"\n",
    ")\n",
    "\n",
    "pred_constr.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb51817",
   "metadata": {},
   "source": [
    "We can now optimize the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efffd1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d5c78",
   "metadata": {},
   "source": [
    "Remember that for the logistic regression, Gurobi does a piecewise-linear\n",
    "approximation of the logistic function. We can therefore get some significant\n",
    "errors when comparing the results of the Gurobi model with what is predicted by\n",
    "the regression.\n",
    "\n",
    "We print the error. Here we need to use `get_error_proba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a2820",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Maximum error in approximating the regression {:.6}\".format(\n",
    "        np.max(pred_constr.get_error())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8fa4d3",
   "metadata": {},
   "source": [
    "The error we get might be considered too large, but we can use Gurobi parameters\n",
    "to tune the piecewise-linear approximation made by Gurobi (at the expense of a\n",
    "harder models).\n",
    "\n",
    "The specific parameters are explained in the documentation of [Functions\n",
    "Constraints](https://www.gurobi.com/documentation/9.1/refman/constraints.html#subsubsection:GenConstrFunction)\n",
    "in Gurobi's manual.\n",
    "\n",
    "We can pass those parameters to the\n",
    "[add_predictor_constr](../api/AbstractPredictorConstr.rst#gurobi_ml.add_predictor_constr)\n",
    "function in the form of a dictionary with the keyword parameter\n",
    "`pwd_attributes`.\n",
    "\n",
    "Now we want a more precise solution, so we remove the current constraint, add a\n",
    "new one that does a tighter approximation and resolve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8706d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_constr.remove()\n",
    "\n",
    "pwl_attributes = {\n",
    "    \"FuncPieces\": -1,\n",
    "    \"FuncPieceLength\": 0.01,\n",
    "    \"FuncPieceError\": 1e-4,\n",
    "    \"FuncPieceRatio\": -1.0,\n",
    "}\n",
    "pred_constr = add_predictor_constr(\n",
    "    m, pipe, feature_vars, y, output_type=\"probability_1\", pwl_attributes=pwl_attributes\n",
    ")\n",
    "\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c7700",
   "metadata": {},
   "source": [
    "We can see that the error has been reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606d2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Maximum error in approximating the regression {:.6}\".format(\n",
    "        np.max(pred_constr.get_error())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c54d0",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "Copyright © 2022 Gurobi Optimization, LLC"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb///ipynb,myst///md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "license": {
   "full_text": "# Copyright © 2022 Gurobi Optimization, LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================="
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
