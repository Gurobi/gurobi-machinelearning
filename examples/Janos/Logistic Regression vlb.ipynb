{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f266b60",
   "metadata": {},
   "source": [
    "# Integrate a logistic regression in a Gurobi model\n",
    "\n",
    "We take the model from JANOS example:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "&\\max \\sum y_i \\\\\n",
    "&\\text{subject to:}\\\\\n",
    "&\\sum x_i \\le 100,\\\\\n",
    "&y_i = g(x_i, X),\\\\\n",
    "& 0.5 z \\le x \\le 2.5 z.\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "Where, $X$ is a vector of known features. And $g$ is a logistic function fitted by scikit-learn to predicts the probabilty that a student will join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce468a1-27be-4bdd-bc78-2204f74bb9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import gurobipy as gp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6bb64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append(\"../../src\")\n",
    "from ml2gurobi.sklearn import PipelinePredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb72e1c",
   "metadata": {},
   "source": [
    "### Do the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve historical data used to do the regression\n",
    "historical_data = pd.read_csv(\"data/college_student_enroll-s1-1.csv\", index_col=0)\n",
    "\n",
    "\n",
    "# classify our features between the ones that are fixed and the ones that will be\n",
    "# part of the optimization problem\n",
    "\n",
    "known_features = [\"SAT\", \"GPA\"]\n",
    "dec_features = [\"scholarship\"]\n",
    "target = \"enroll\"\n",
    "features = known_features + dec_features\n",
    "\n",
    "historical_data = historical_data[features + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b554b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run our regression\n",
    "X = historical_data.loc[:, features]\n",
    "Y = historical_data.loc[:, \"enroll\"]\n",
    "scaler = StandardScaler()\n",
    "regression = LogisticRegression(random_state=0, solver=\"lbfgs\")\n",
    "pipe = make_pipeline(scaler, regression)\n",
    "pipe.fit(X=X, y=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7293c95",
   "metadata": {},
   "source": [
    "### Do the optimization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab53b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve new data used to build the optimization problem\n",
    "studentsdata = pd.read_csv(\"data/admissions500.csv\", index_col=0)\n",
    "studentsdata = studentsdata[known_features]\n",
    "nstudents = studentsdata.shape[0]\n",
    "\n",
    "# Start with classical part of the model\n",
    "m = gp.Model()\n",
    "\n",
    "knownidx = historical_data.columns.get_indexer(known_features)\n",
    "scholarshipidx = historical_data.columns.get_indexer(dec_features)\n",
    "\n",
    "lb = np.zeros((nstudents, len(features)))\n",
    "ub = np.ones((nstudents, len(features))) * gp.GRB.INFINITY\n",
    "lb[:, knownidx] = studentsdata.loc[:, known_features]\n",
    "ub[:, knownidx] = studentsdata.loc[:, known_features]\n",
    "\n",
    "x = m.addMVar(lb.shape, lb=lb, ub=ub, name=\"x\")\n",
    "scholarship = x[:, scholarshipidx][:, 0]\n",
    "y = m.addMVar(nstudents, ub=1, name=\"y\")\n",
    "z = m.addMVar(nstudents, vtype=gp.GRB.BINARY)\n",
    "\n",
    "scholarship.LB = 0.0\n",
    "scholarship.UB = 2.5\n",
    "\n",
    "m.setObjective(y.sum(), gp.GRB.MAXIMIZE)\n",
    "m.addConstr(scholarship.sum() <= 0.2 * nstudents)\n",
    "m.addConstr(scholarship <= 2.5 * z[:])\n",
    "m.addConstr(scholarship >= 0.5 * z[:])\n",
    "\n",
    "PipelinePredictor(m, pipe, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b9d06",
   "metadata": {},
   "source": [
    "### Finally optimize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa1b1c2-5591-4de9-9553-e681dd999bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3208ac31",
   "metadata": {},
   "source": [
    "### Look at the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95828b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what we predicted\n",
    "plt.scatter(scholarship.X, y.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf73498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the historical data\n",
    "plt.scatter(X.loc[:, \"scholarship\"], pipe.predict_proba(X)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of students offered a scholarship\n",
    "print(\n",
    "    \"In historical data {:.4}% students offered a scholarship\".format(\n",
    "        100 * ((X.loc[:, \"scholarship\"] > 0).sum() / len(X.loc[:, \"scholarship\"]))\n",
    "    )\n",
    ")\n",
    "print(\"In our solution {:.4}% students offered a scholarship\".format(100 * sum(scholarship.X > 0) / nstudents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10 = historical_data.sort_values(by=[\"GPA\"])[:2000]\n",
    "\n",
    "top10 = historical_data.sort_values(by=[\"GPA\"])[-2000:]\n",
    "\n",
    "top10.enroll.sum()\n",
    "\n",
    "print(\"In historical data\")\n",
    "print(\n",
    "    \"Among top 10% students: {}% were offered a scholarship and {}% joined\".format(\n",
    "        100 * (top10.scholarship > 0).sum() / top10.shape[0],\n",
    "        100 * (top10.enroll.sum() / top10.shape[0]),\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Among bottom 10% students: {}% were offered a scholarship and {}% joined\".format(\n",
    "        100 * (bottom10.scholarship > 0).sum() / bottom10.shape[0],\n",
    "        100 * (bottom10.enroll.sum() / bottom10.shape[0]),\n",
    "    )\n",
    ")\n",
    "\n",
    "Xpredicted = pd.concat(\n",
    "    [\n",
    "        studentsdata,\n",
    "        pd.DataFrame(scholarship.X, columns=[\"scholarship\"], index=studentsdata.index),\n",
    "        pd.DataFrame(y.X, columns=[\"enroll\"], index=studentsdata.index),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "top10 = Xpredicted.sort_values(by=\"GPA\")[-50:]\n",
    "bottom10 = Xpredicted.sort_values(by=\"GPA\")[:50]\n",
    "\n",
    "print(\"In predicted data\")\n",
    "print(\n",
    "    \"Among top 10% students: {:.4}% were offered a scholarship and {:.4}% joined\".format(\n",
    "        100 * (top10.scholarship > 0).sum() / top10.shape[0],\n",
    "        100 * (top10.enroll.sum() / top10.shape[0]),\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Among bottom 10% students: {:.4}% were offered a scholarship and {:.4}% joined\".format(\n",
    "        100 * (bottom10.scholarship > 0).sum() / bottom10.shape[0],\n",
    "        100 * (bottom10.enroll.sum() / bottom10.shape[0]),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bf1557-df66-492a-97b7-c7155bc13477",
   "metadata": {},
   "source": [
    "Copyright Â© 2022 Gurobi Optimization, LLC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
