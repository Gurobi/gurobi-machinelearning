{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f7d69f9",
   "metadata": {
    "id": "7f7d69f9"
   },
   "source": [
    "Copyright © 2022 Gurobi Optimization, LLC\n",
    "\n",
    "# How Much Is Too Much? Avocado Pricing and Supply Using Mathematical Optimization\n",
    "*Note: The resulting model in this example will be too large for a size-limited license; in order to solve it, please visit https://www.gurobi.com/free-trial for a full license*\n",
    "\n",
    "A [Food Network article](https://www.foodnetwork.com/fn-dish/news/2018/3/avocado-unseats-banana-as-america-s-top-fruit-import-by-value) from March 2017 declared, \"Avocado unseats banana as America's top fruit import.\" This declaration is incomplete and debatable for reasons other than whether  avocado is a fruit. Avocados are expensive.\n",
    "\n",
    "As a supplier, setting an appropriate avocado price requires a delicate trade-off. \n",
    "Set it too high and you lose customers. Set it too low and you won't make a profit.\n",
    "Equipped with good data, the avocado pricing and supply problem is *ripe* with opportunities for demonstrating the power of optimization and data science.\n",
    "\n",
    "They say when life gives you avocados, make guacamole.\n",
    "Just like the perfect guacamole needs the right blend of onion, lemon and spices, finding an optimal avocado price needs the right blend of descriptive, predictive and prescriptive analytics.\n",
    "\n",
    "|<img src=\"https://github.com/Gurobi/modeling-examples/blob/master/price_optimization/avocado_image_grocery.jpeg?raw=1\" width=\"500\" align=\"center\">| \n",
    "|:--:|\n",
    "| <b>Avocados: a quintessential corner of a grocery store. Image Credits: [New York Post](https://nypost.com/2022/02/15/us-will-halt-mexico-avocado-imports-as-long-as-necessary/) </b>| \n",
    "\n",
    "\n",
    "**Goal**: Develop a data science pipeline for pricing and distribution of avocados to maximize revenue.\n",
    "\n",
    "This notebook walks through a decision-making pipeline that culminates in a mathematical optimization model.\n",
    "There are three stages: \n",
    "- First, understand the dataset and infer the relationships between categories such as the sales, price, region, and seasonal trends.\n",
    "- Second, build a prediction model that predicts the demand for avocados as a function of price, region, year and the seasonality.\n",
    "- Third, design an optimization problem that sets the optimal price and supply quantity to maximize the net revenue while incorporating costs for wastage and transportation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5dc427",
   "metadata": {
    "id": "2e5dc427"
   },
   "source": [
    "## Load the Packages and the Datasets\n",
    "\n",
    "We use real sales data provided by the [Hass Avocado Board](https://hassavocadoboard.com/) (HAB), whose aim is to \"make avocados America’s most popular fruit\". This dataset contains consolidated information on several years' worth of market prices and sales of avocados. \n",
    "\n",
    "We will now load the following packages for analyzing and visualizing the data.\n",
    "\n",
    "\n",
    "### Extra required packages\n",
    "- seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3024295a",
   "metadata": {
    "id": "3024295a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree \n",
    "import seaborn as sns\n",
    "import sklearn \n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4537e1ae",
   "metadata": {
    "id": "4537e1ae"
   },
   "source": [
    "The dataset from HAB contains sales data for the years 2019-2022. This data is augmented by a previous download from HAB available on [Kaggle](https://www.kaggle.com/datasets/timmate/avocado-prices-2020) with sales for the years 2015-2018.\n",
    "\n",
    "Each row in the dataset is the weekly number of avocados sold and the weekly average price of an avocado categorized by region and type of avocado. There are two types of avocados: conventional and organic. In this notebook, we will only consider the conventional avocados.\n",
    "There are eight large regions, namely the Great Lakes, Midsouth, North East, Northern New England, South Central, South East, West and Plains.\n",
    "\n",
    "Now, load the data and store into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ebd6bb",
   "metadata": {
    "id": "d7ebd6bb",
    "outputId": "17377895-8cf1-43fb-e827-43e0c72e8b4b"
   },
   "outputs": [],
   "source": [
    "avocado = pd.read_csv('https://raw.githubusercontent.com/Gurobi/modeling-examples/master/price_optimization/HABdata_2019_2022.csv') # dataset downloaded directly from HAB\n",
    "avocado_old = pd.read_csv('https://raw.githubusercontent.com/Gurobi/modeling-examples/master/price_optimization/kaggledata_till2018.csv') # dataset downloaded from Kaggle\n",
    "avocado = avocado.append(avocado_old, ignore_index=True)\n",
    "avocado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68efc9c1",
   "metadata": {
    "id": "68efc9c1"
   },
   "source": [
    "## Prepare the Dataset\n",
    "\n",
    "We will now prepare the data for making sales predictions. Add new columns to the dataframe for the year and seasonality. Let each year from 2015 through 2022 be given an index from 0 through 7 in the increasing order of the year. We will define the peak season to be the months of February through July. These months are set based on visual inspection of the trends, but you can try setting other months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09a61a",
   "metadata": {
    "id": "cd09a61a",
    "outputId": "f213e584-905d-4488-a603-554565940b5b"
   },
   "outputs": [],
   "source": [
    "# Add the index for each year from 2015 through 2022\n",
    "avocado['date'] = pd.to_datetime(avocado['date'])\n",
    "avocado['year'] = pd.DatetimeIndex(avocado['date']).year\n",
    "avocado['year_index'] = avocado['year'] - 2015\n",
    "avocado = avocado.sort_values(by='date')\n",
    "\n",
    "# Define the peak season\n",
    "avocado['month'] = pd.DatetimeIndex(avocado['date']).month\n",
    "peak_months = range(2,8)        # <--------- Set the months for the \"peak season\"\n",
    "def peak_season(row):\n",
    "    return 1 if int(row['month']) in peak_months else 0  \n",
    "\n",
    "avocado['peak'] = avocado.apply(lambda row: peak_season(row), axis=1)\n",
    "\n",
    "# Scale the number of avocados to millions\n",
    "avocado['units_sold'] = avocado['units_sold']/1000000\n",
    "\n",
    "# Select only conventional avocados\n",
    "avocado = avocado[avocado['type'] == 'Conventional'] \n",
    "\n",
    "avocado = avocado[['date','units_sold','price','region','year','month','year_index','peak']].reset_index(drop = True)\n",
    "\n",
    "avocado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bb1d21",
   "metadata": {
    "id": "65bb1d21"
   },
   "source": [
    "## Part 1: Observe Trends in the Data\n",
    "\n",
    "Now, we will infer sales trends in time and seasonality. For simplicity, let's proceed with data from the United States as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c4402",
   "metadata": {
    "id": "ab0c4402"
   },
   "outputs": [],
   "source": [
    "df_Total_US = avocado[avocado['region']=='Total_US']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903d4b5",
   "metadata": {
    "id": "7903d4b5"
   },
   "source": [
    "### Sales Over the Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec7e699",
   "metadata": {
    "id": "2ec7e699",
    "outputId": "c35c2eb0-068c-42db-f632-9bfa4c246348"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 5)) \n",
    "\n",
    "mean = df_Total_US.groupby('year')['units_sold'].mean()\n",
    "std  = df_Total_US.groupby('year')['units_sold'].std()\n",
    "axes.errorbar(mean.index, mean, xerr=0.5, yerr=2*std, linestyle='') \n",
    "axes.set_ylabel('Units Sold (millions)')\n",
    "axes.set_xlabel('Year') \n",
    " \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ba680",
   "metadata": {
    "id": "e37ba680"
   },
   "source": [
    "We can see that the sales generally increased over the years, albeit marginally. The dip in 2019 is the effect of the well-documented [2019 avocado shortage](https://abc7news.com/avocado-shortage-season-prices/5389855/) that led to avocados [nearly doubling in price.](https://abc7news.com/avocado-shortage-season-prices/5389855/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30abfba6",
   "metadata": {
    "id": "30abfba6"
   },
   "source": [
    "### Seasonality\n",
    "\n",
    "We will now see the sales trends within a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a594510",
   "metadata": {
    "id": "4a594510",
    "outputId": "fcfa4272-a70e-4bec-9e92-140c5646a4e2"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 5)) \n",
    "\n",
    "mean = df_Total_US.groupby('month')['units_sold'].mean()\n",
    "std  = df_Total_US.groupby('month')['units_sold'].std()\n",
    " \n",
    "axes.errorbar(mean.index, mean, xerr=0.5, yerr=2*std, linestyle='') \n",
    "axes.set_ylabel('Units Sold (millions)')\n",
    "axes.set_xlabel('Month') \n",
    " \n",
    "fig.tight_layout()\n",
    " \n",
    "plt.xlabel('Month')\n",
    "axes.set_xticks(range(1,13)) \n",
    "plt.ylabel('Units sold (millions)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87738d0",
   "metadata": {
    "id": "c87738d0"
   },
   "source": [
    "We see a Super Bowl peak in February and a Cinco de Mayo peak in May. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e04cef1",
   "metadata": {
    "id": "2e04cef1"
   },
   "source": [
    "### Correlations\n",
    "\n",
    "Now, we will see how the variables are correlated with each other.\n",
    "The end goal is to predict sales given the price of an avocado, year and seasonality (peak or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25729f7d",
   "metadata": {
    "id": "25729f7d",
    "outputId": "069d58c0-9310-4223-cfef-928eae5bc69e"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(15, 5)) \n",
    "sns.heatmap(df_Total_US[['units_sold', 'price', 'year', 'peak']].corr(),annot=True, center=0,ax=axes) \n",
    "\n",
    "axes.set_title('Correlations for conventional avocados') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48eecb",
   "metadata": {
    "id": "fe48eecb"
   },
   "source": [
    "As expected, the sales quantity has a negative correlation with the price per avocado. The sales quantity has a positive correlation with the year and season being a peak season."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27356cce",
   "metadata": {
    "id": "27356cce"
   },
   "source": [
    "### Regions\n",
    "\n",
    "Finally, we will see how the sales differ among the different regions. This will determine the number of avocados that we want to supply to each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b3f31",
   "metadata": {
    "id": "081b3f31",
    "outputId": "753fd7a7-5c0d-40fc-b17d-f606b1592254"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 5)) \n",
    "\n",
    "regions = ['Great_Lakes','Midsouth','Northeast','Northern_New_England','SouthCentral','Southeast','West','Plains'] \n",
    "df = avocado[avocado.region.isin(regions)]  \n",
    "\n",
    "mean = df.groupby('region')['units_sold'].mean()\n",
    "std  = df.groupby('region')['units_sold'].std() \n",
    " \n",
    "axes.errorbar(range(len(mean)), mean, xerr=0.5, yerr=2*std, linestyle='')  \n",
    "\n",
    "fig.tight_layout()\n",
    " \n",
    "plt.xlabel('Region') \n",
    "plt.xticks(range(len(mean)), pd.DataFrame(mean)['units_sold'].index,rotation=20)\n",
    "plt.ylabel('Units sold (millions)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a2716",
   "metadata": {
    "id": "1d1a2716"
   },
   "source": [
    "Clearly, west-coasters love avocados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e125e",
   "metadata": {
    "id": "b20e125e"
   },
   "source": [
    "## Part II: Predict the Sales\n",
    "\n",
    "The trends observed in Part I motivate us to construct a prediction model for sales using the independent variables- price, year, region and seasonality.\n",
    "Henceforth, the sales quantity will be referred to as the *predicted demand*.\n",
    "\n",
    "Let us now construct a linear regressor for the demand.\n",
    "Note that the region is a categorical variable.\n",
    "The linear regressor can be mathematically expressed as:\n",
    "\n",
    "$$demand = \\beta_0 + \\beta_1 * price + \\sum\\limits_{region} \\beta^{region}_3 * \\mathbb{1}(region)  +  \\beta_4 w_{year}*year +  \\beta_5  * \\mathbb{1}(peak).$$\n",
    "\n",
    "Here, the $\\beta$ values are weights (or \"co-efficients\") that have to be learned from the data. \n",
    "Note that the notation $\\mathbb{1}(region)$ is an indicator function that takes the value $1$ for each region in the summation. The value of $\\mathbb{1}(peak)$ is $1$ if we consider the peak season.\n",
    "\n",
    "To validate the regression model, we will randomly split the dataset into $80\\%$ training and $20\\%$ testing data and learn the weights using sklearns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c84bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from gurobi_ml import add_predictor_constr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'units_sold'\n",
    "features = ['price', 'year_index', 'region', 'peak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:, target]\n",
    "X = df.loc[:, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = make_column_transformer((OneHotEncoder(drop=\"first\"), ['region']), remainder='passthrough',\n",
    "                                    verbose_feature_names_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transform.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98cea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98badcd",
   "metadata": {
    "id": "55a07590",
    "outputId": "1064f3f2-1552-43d6-c010-632614417089"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "pipeline = make_pipeline(StandardScaler(), MLPRegressor([10]*2))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Get R^2 from test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"The R^2 value in the test set is\",r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e085dad",
   "metadata": {
    "id": "1e085dad"
   },
   "source": [
    "We can observe a good $R^2$ value in the test set. We will now train the fit the weights to the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c8804",
   "metadata": {
    "id": "506c8804",
    "outputId": "8f28dc55-c8c5-4f9e-9dce-11ba544cbe6d"
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X, y)\n",
    "\n",
    "y_pred_full = pipeline.predict(X)\n",
    "print(\"The R^2 value in the full dataset is\",r2_score(y, y_pred_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbe1cd5",
   "metadata": {
    "id": "7cbe1cd5"
   },
   "source": [
    "## Part III: Optimize for Price and Supply of Avocados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214906e5",
   "metadata": {
    "id": "214906e5"
   },
   "source": [
    "Knowing how the price of an avocado affects the demand, how can we set the optimal avocado price? \n",
    "We don't want to set the price too high, since that could drive demand and sales down. At the same time, setting the price too low could be sub-optimal when maximizing revenue. So what is the sweet spot? \n",
    "\n",
    "On the distribution logistics, we want to make sure that there are enough avocados across the regions. We can address these considerations in a mathematical optimization model.\n",
    "An optimization model finds the **best solution** according to an **objective function** such that the solution satisfies a set of **constraints**. \n",
    "Here, a solution is expressed as a vector of real values or integer values called **decision variables**.\n",
    "Constraints are a set of equations or inequalities written as a function of the decision variables.\n",
    "\n",
    "At the start of each week, assume that the total number of available products is finite. This quantity needs to be distributed to the various regions while maximizing net revenue. So there are two key decisions - the price of an avocado in each region, and the number of avocados allocated to each region. \n",
    "\n",
    "Let us now define some input parameters and notations used for creating the model. The subscript $r$ will be used to denote each region.\n",
    "\n",
    "### Input Parameters\n",
    "- $R$: set of regions,\n",
    "- $d(p,r)$: predicted demand in region $r\\in R$ when the avocado per product is $p$, \n",
    "- $B$: available avocados to be distributed across the regions, \n",
    "- $c_{waste}$: cost ($\\$$) per wasted avocado,\n",
    "- $c^r_{transport}$: cost ($\\$$) of transporting a avocado to region $r \\in R$,\n",
    "- $a^r_{min},a^r_{max}$: minimum and maximum price ($\\$$) per avocado for reigon $r \\in R$,\n",
    "- $b^r_{min},b^r_{max}$: minimum and maximum number of avocados allocated to region $r \\in R$,\n",
    "\n",
    "The following code loads the Gurobi python package and initiates the optimization model. \n",
    "The value of $B$ is set to $30$ million avocados, which is close to the average weekly supply value from the data.\n",
    "For illustration, let us consider the peak season of 2021.\n",
    "The cost of wasting an avocado is set to $\\$0.10$.\n",
    "The cost of transporting an avocado ranges between $\\$0.10$ to $\\$0.50$ based on each region's distance from the southern border, where the [majority of avocado supply comes from](https://www.britannica.com/plant/avocado).\n",
    "Further, we can set the price of an avocado to not exceed $\\$ 2$ apiece. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29328983",
   "metadata": {
    "id": "29328983",
    "outputId": "a9367322-15df-4a39-c1d0-e365e006cc12"
   },
   "outputs": [],
   "source": [
    "import gurobipy as gp \n",
    "from gurobipy import GRB\n",
    "\n",
    "m = gp.Model(\"Avocado_Price_Allocation\")\n",
    "\n",
    "# Sets and parameters\n",
    "R = len(regions)   # set of all regions\n",
    "\n",
    "B = 30  # total amount ot avocado supply\n",
    "\n",
    "peak_or_not = 1 # 1 if it is the peak season; 1 if isn't\n",
    "year = 2022\n",
    "\n",
    "c_waste = 0.1 # the cost ($) of wasting an avocado\n",
    "\n",
    "# the cost of transporting an avocado\n",
    "c_transport = pd.Series({'Great_Lakes': .3,\n",
    "                                      'Midsouth':.1,\n",
    "                                      'Northeast':.4,\n",
    "                                      'Northern_New_England':.5,\n",
    "                                      'SouthCentral':.3,\n",
    "                                      'Southeast':.2,\n",
    "                                      'West':.2,\n",
    "                                      'Plains':.2})\n",
    "# Get the lower and upper bounds from the dataset for the price and the number of products to be stocked \n",
    "a_min = 0 # minimum avocado price in each region \n",
    "a_max = 2 # maximum avocado price in each region \n",
    "b_min = df.groupby('region')['units_sold'].min().loc[regions]  # minimum number of avocados allocated to each region\n",
    "b_max = df.groupby('region')['units_sold'].max().loc[regions]   # maximum number of avocados allocated to each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcde878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bounds for the features\n",
    "\n",
    "# First create a data frame indexed by the regions and with the features\n",
    "# as columns\n",
    "feat_bounds = pd.DataFrame(index=regions, columns=features)\n",
    "feat_bounds.loc[:, 'price'] = a_min\n",
    "feat_bounds.loc[:, 'peak'] = peak_or_not\n",
    "feat_bounds.loc[:, 'year_index'] = year - 2015\n",
    "for r in regions:\n",
    "    feat_bounds.loc[r, 'region'] = r\n",
    "\n",
    "# Now we use our transform to transform the data to the space of the regression\n",
    "feat_bounds = pd.DataFrame(data=transform.transform(feat_bounds), columns=transform.get_feature_names_out())\n",
    "\n",
    "# Finally we can store the bounds\n",
    "# Price is the only feature that is not fixed and has a different upper bound\n",
    "feat_lb = feat_bounds.copy()\n",
    "feat_bounds.loc[:, 'price'] = a_max\n",
    "feat_ub = feat_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa17930",
   "metadata": {
    "id": "1fa17930"
   },
   "source": [
    "### Decision Variables\n",
    "\n",
    "Let us now define the decision variables.\n",
    "In our model, we want to store the price and number of avocados allocated to each region. We also want variables that track how many avocados are predicted to be sold and how many are predicted to be wasted. \n",
    "The following notation is used to model these decision variables, indexed for each region $r$.\n",
    "\n",
    "$p_r$: the price of an avocado ($\\$$) in region $r$,\n",
    "\n",
    "$x_r$: the number of products avocados supplied to region $r$,\n",
    "\n",
    "$s_r = \\min \\{x_r,d_r(p_r)\\}$: the predicted number of avocados sold in region $r$, \n",
    "\n",
    "$w_r = x_r - s_r$: the predicted number of avocados wasted in region $r$\n",
    "\n",
    "We will now add the variables to the Gurobi model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb7f0f8",
   "metadata": {
    "id": "0bb7f0f8"
   },
   "outputs": [],
   "source": [
    "x = m.addMVar(R,name=\"x\",lb=b_min,ub=b_max)  # quantity supplied to each region\n",
    "s = m.addMVar(R,name=\"s\",lb=0)   # predicted amount of sales in each region for the given price\n",
    "w = m.addMVar(R,name=\"w\",lb=0)   # excess wasteage in each region\n",
    "\n",
    "# Add variables for the regression\n",
    "feats = m.addMVar((R, X.shape[1]), lb=feat_lb.to_numpy(), ub=feat_ub.to_numpy(), name='reg_features')\n",
    "d = m.addMVar((R), lb=-gp.GRB.INFINITY, name='reg_output')\n",
    "\n",
    "# Get the price variables from the features of the regression\n",
    "price_index = transform.get_feature_names().index('price')\n",
    "p = feats[:, price_index]\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d733d6f",
   "metadata": {
    "id": "3d733d6f"
   },
   "source": [
    "### Set the Objective\n",
    "\n",
    "Next, we will define the objective function: we want to maximizing the **net revenue**. The revenue from sales in each region is calculated by the price of an avocado in that region multiplied by the quantity sold there. There are two types of costs incurred: the wastage costs for excess unsold avocados and the cost of transporting the avocados to the different regions. \n",
    "\n",
    "The net revenue is the sales revenue subtracted by the total costs incurred. We assume that the purchase costs are fixed and are not incorporated in this model.\n",
    "\n",
    "Using the defined decision variables, the objective can be written as follows.\n",
    "\n",
    "\\begin{align}\n",
    "\\textrm{maximize} &  \\sum_{r}  (p_r * s_r - c_{waste} * w_r - c^r_{transport} * x_r)& \n",
    "\\end{align}\n",
    "\n",
    "Let us now add the objective function to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5e1218",
   "metadata": {
    "id": "bb5e1218"
   },
   "outputs": [],
   "source": [
    "m.setObjective(p@s - c_waste * w.sum()- c_transport.to_numpy() @ x) \n",
    "m.ModelSense = GRB.MAXIMIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a8432c",
   "metadata": {
    "id": "93a8432c"
   },
   "source": [
    "### Add the Supply Constraint\n",
    "\n",
    "We now introduce the constraints. The first constraint is to make sure that the total number of avocados supplied is equal to $B$, which can be mathematically expressed as follows.\n",
    "\n",
    "\\begin{align*} \n",
    "\\sum_{r} x_r &= B\n",
    "\\end{align*}\n",
    "\n",
    "The following code adds this constraint to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bd6017",
   "metadata": {
    "id": "84bd6017"
   },
   "outputs": [],
   "source": [
    "m.addConstr(x.sum() == B)\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380cbfab",
   "metadata": {
    "id": "380cbfab"
   },
   "source": [
    "### Add Constraints That Define Sales Quantity\n",
    "\n",
    "Next, we should define the predicted sales quantity in each region.\n",
    "We can assume that if we supply more than the predicted demand, we sell exactly the predicted demand. \n",
    "Otherwise, we sell exactly the allocated amount.\n",
    "Hence, the predicted sales quantity is the minimum of the allocated quantity and the predicted demand, i.e., $s_r = \\min \\{x_r,d_r(p_r)\\}$. \n",
    "This relationship can be modeled by the following two constraints for each region $r$.\n",
    "\n",
    "\\begin{align*} \n",
    "s_r &\\leq x_r  \\\\\n",
    "s_r &\\leq d(p_r,r)  \n",
    "\\end{align*}\n",
    "\n",
    "These constraints will ensure that the sales quantity $s_r$ in region $r$ is  greater than neither the allocated quantity nor the predicted demand. Note that the maximization objective function tries to maximize the revenue from sales, and therefore the optimizer will maximize the predicted sales quantity. This is assuming that the surplus and transportation costs are less than the sales price per avocado. Hence, these constraints along with the objective will ensure that the sales are equal to the minimum of supply and predicted demand.\n",
    "\n",
    "Let us now add these constraints to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72fc5b",
   "metadata": {
    "id": "ca72fc5b"
   },
   "outputs": [],
   "source": [
    "m.addConstr(s <= x)\n",
    "m.addConstr(s <= d) \n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0875f6c",
   "metadata": {
    "id": "d0875f6c"
   },
   "source": [
    "### Add the Wastage Constraints\n",
    "\n",
    "Finally, we should define the predicted wastage in each region, given by the supplied quantity that is not predicted to be sold. We can express this mathematically for each region $r$.\n",
    "\n",
    "\\begin{align*} \n",
    "w_r &= x_r - s_r\n",
    "\\end{align*} \n",
    "\n",
    "We can add these constraints to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac8066",
   "metadata": {
    "id": "38ac8066"
   },
   "outputs": [],
   "source": [
    "m.addConstr(w == x - s)\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_constr = add_predictor_constr(m, pipeline, feats, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881beca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_constr.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab6884c",
   "metadata": {
    "id": "dab6884c"
   },
   "source": [
    "### Fire Up the Solver\n",
    "\n",
    "We have added the decision variables, objective function, and the constraints to the model. \n",
    "The model is ready to be solved.\n",
    "Before we do so, we should let the solver know what type of model this is.\n",
    "The default setting assumes that the objective and the constraints are linear functions of the variables.\n",
    "\n",
    "In our model, the objective is **quadratic** since we take the product of price and the predicted sales, both of which are variables. \n",
    "Maximizing a quadratic term is said to be **non-convex**, and we specify this using a Gurobi parameter value to be $2$. \n",
    "See [here](https://www.gurobi.com/documentation/9.5/refman/nonconvex.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c5eca",
   "metadata": {
    "id": "ac3c5eca",
    "outputId": "e83ff570-7f4e-474f-8141-fbe04f433ce6"
   },
   "outputs": [],
   "source": [
    "m.Params.NonConvex = 2\n",
    "m.optimize() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e96b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Maximal error in predicted values in solution {np.max(np.abs(pred_constr.get_error()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed67953",
   "metadata": {
    "id": "aed67953"
   },
   "source": [
    "The solver solved the optimization problem in less than a second.\n",
    "Let us now analyze the optimal solution by storing it in a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ff154",
   "metadata": {
    "id": "3f7ff154",
    "outputId": "49ee3598-a7af-4b72-9d3f-1b917668e9de"
   },
   "outputs": [],
   "source": [
    "solution = pd.DataFrame() \n",
    "solution['Region'] = regions\n",
    "solution['Price'] = p.X\n",
    "solution['Allocated'] = x.X.round(4)\n",
    "solution['Sold'] = s.X.round(4)\n",
    "solution['Wasted'] = w.X.round(4)\n",
    "solution['Pred_demand'] = d.X.round(4)\n",
    "\n",
    "opt_revenue = m.ObjVal\n",
    "print(\"\\n The optimal net revenue: $%f million\"%opt_revenue) \n",
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f475012d",
   "metadata": {
    "id": "f475012d"
   },
   "source": [
    "Let us now visualize a scatter plot between the price and the number of avocados sold (in millions) for the eight regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551f4eb6",
   "metadata": {
    "id": "551f4eb6",
    "outputId": "6a61de51-b332-4a6b-cee1-f7df96d7055d"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1) \n",
    "plot_sol = sns.scatterplot(data=solution,x='Price',y='Sold',hue='Region',s=100)\n",
    "plot_waste = sns.scatterplot(data=solution,x='Price',y='Wasted',marker='x',hue='Region',s=100,legend = False)\n",
    "\n",
    "plot_sol.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plot_waste.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.ylim(0, 5)\n",
    "plt.xlim(1, 2.2)\n",
    "ax.set_xlabel('Price per avocado ($)')\n",
    "ax.set_ylabel('Number of avocados sold (millions)')\n",
    "plt.show() \n",
    "print(\"The circles represent sales quantity and the cross markers represent the wasted quantity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0d2b24",
   "metadata": {
    "id": "ed0d2b24"
   },
   "source": [
    "## Experiment with Parameter Settings\n",
    "\n",
    "While this notebook walked through how to build an optimization model piece-by-piece, the following code contains the overall optimization model. You can input different parameter values and see how the optimal solution changes. \n",
    "The value of $B$ can be controlled using the slider below the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8208d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(10, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='relu'),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "nn.compile(optimizer=tf.keras.optimizers.Adam(0.1),\n",
    "           loss='mean_absolute_error')\n",
    "nn.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, y_test),\n",
    ")\n",
    "y_pred = nn.predict(X_test)\n",
    "print(\"The R^2 value in the test set is\",r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b09be2b",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "25bfc9bd60d7463eabaec1397320e046"
     ]
    },
    "id": "26fc6a49",
    "outputId": "30b4f677-94f7-4cd0-b565-d34856e5612c"
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets \n",
    " \n",
    "import plotly.express as px\n",
    "\n",
    "# Sets and parameters\n",
    "\n",
    "peak_or_not = 1 # \n",
    "year = 2021\n",
    "\n",
    "# Sets and parameters\n",
    "R = len(regions)   # set of all regions\n",
    "c_waste = 0.1\n",
    "# the cost of transporting an avocado\n",
    "c_transport = pd.Series({'Great_Lakes': .3,\n",
    "                                      'Midsouth':.1,\n",
    "                                      'Northeast':.4,\n",
    "                                      'Northern_New_England':.5,\n",
    "                                      'SouthCentral':.3,\n",
    "                                      'Southeast':.2,\n",
    "                                      'West':.2,\n",
    "                                      'Plains':.2})\n",
    "\n",
    "# Get the lower and upper bounds from the dataset for the price and the number of products to be stocked \n",
    "a_min = 0 # minimum avocado price in each region \n",
    "a_max = 2 # maximum avocado price in each region \n",
    "b_min = df.groupby('region')['units_sold'].min().loc[regions]  # minimum number of avocados allocated to each region\n",
    "b_max = df.groupby('region')['units_sold'].max().loc[regions]   # maximum number of avocados allocated to each region\n",
    "\n",
    "def build_MIQP(regressor):\n",
    "    B = 30\n",
    "    \n",
    "    # Initialize Model\n",
    "    m = gp.Model(\"Avocado_Price_Allocation\")\n",
    "\n",
    "    x = m.addMVar(R,name=\"x\",lb=b_min,ub=b_max)  # quantity supplied to each region\n",
    "    s = m.addMVar(R,name=\"s\",lb=0)   # predicted amount of sales in each region for the given price\n",
    "    w = m.addMVar(R,name=\"w\",lb=0)   # excess wasteage in each region\n",
    "\n",
    "    feats = m.addMVar((R, X.shape[1]), lb=feat_lb.to_numpy(), ub=feat_ub.to_numpy(), name='reg_features')\n",
    "    d = m.addMVar((R), lb=-gp.GRB.INFINITY, name='reg_output')\n",
    "\n",
    "    # Get the price variables from the features of the regression\n",
    "    price_index = transform.get_feature_names().index('price')\n",
    "    p = feats[:, price_index]\n",
    "    m.update()\n",
    "    \n",
    "    # Set upper bound for the feature that is not fixed\n",
    "    p.UB = 2.0\n",
    "    m.update()\n",
    "    \n",
    "    # Set the objective\n",
    "    m.setObjective(p@s - c_waste * w.sum()- c_transport.to_numpy() @ x) \n",
    "    m.ModelSense = GRB.MAXIMIZE\n",
    "    # Add the constraints \n",
    "    m.addConstr(s <= x)\n",
    "    m.addConstr(s <= d) \n",
    "    m.addConstr(x == w + s)\n",
    "    budget = m.addConstr(x.sum() == B)\n",
    "    pred_consrt = add_predictor_constr(m, pipeline, feats, d)\n",
    "\n",
    "    # Solve   \n",
    "    m.setParam('OutputFlag', 0)\n",
    "    m.Params.NonConvex = 2\n",
    "    m.update()\n",
    "    return (m, budget,\n",
    "            {'p':p, 'x':x, 's':s, 'w':w, 'd':d})\n",
    "\n",
    "def solve_MIQP(x, m, budget, variables):\n",
    "    budget.RHS = x\n",
    "\n",
    "    m.optimize() \n",
    "    if m.status == 4:\n",
    "        print('The problem is infeasible. Try changing the parameter values.')\n",
    "    else:\n",
    "        global solution, opt_revenue\n",
    "        solution = pd.DataFrame() \n",
    "        solution['Region'] = regions\n",
    "        solution['Price'] = variables['p'].X.round(4)\n",
    "        solution['Allocated'] = variables['x'].X.round(4)\n",
    "        solution['Sold'] = variables['s'].X.round(4)\n",
    "        solution['Wasted'] = variables['w'].X.round(4)\n",
    "        solution['Demand'] = variables['d'].X.round(4)\n",
    "\n",
    "        opt_revenue = m.ObjVal\n",
    "        if display_figures:\n",
    "            print(\"\\n Net revenue: $%f million\"%opt_revenue)\n",
    "            print(\"\\nThe optimal solution is as follows. Price per avocado in dollars. Allocated avocados, wasted avocados, and predicted demand in millions.\\n\")\n",
    "            print(solution)\n",
    "            \n",
    "            print(\"\\n Scatter plot of price vs number of avocados sold (millions) for the eight regions:\")\n",
    "            fig, ax = plt.subplots(1,1) \n",
    "            plot_sol = sns.scatterplot(data=solution,x='Price',y='Sold',hue='Region',s=100)\n",
    "            plot_waste = sns.scatterplot(data=solution,x='Price',y='Wasted',marker='x',hue='Region',s=100,legend = False)\n",
    "\n",
    "            plot_sol.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "            plot_waste.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "            plt.ylim(0, 5)\n",
    "            plt.xlim(1, 2.2)\n",
    "            ax.set_xlabel('Price per avocado ($)')\n",
    "            ax.set_ylabel('Number of avocados sold (millions)')\n",
    "            plt.show() \n",
    "            print(\"The circles represent sales quantity and the cross markers represent the wasted quantity.\")\n",
    "            \n",
    "            \n",
    "        return m.ObjVal, solution\n",
    "        \n",
    "        \n",
    "display_figures = 1\n",
    "m, budget, variables = build_MIQP(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc6a49",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "25bfc9bd60d7463eabaec1397320e046"
     ]
    },
    "id": "26fc6a49",
    "outputId": "30b4f677-94f7-4cd0-b565-d34856e5612c"
   },
   "outputs": [],
   "source": [
    "print(\"Select a value for the available inventory (B) (in millions):\\n\")\n",
    "interact(solve_MIQP, x=(15,40,1), m=fixed(m), budget=fixed(budget), variables=fixed(variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05d06ab",
   "metadata": {
    "id": "d05d06ab"
   },
   "source": [
    "**Observations**:\n",
    "- When the supply is highly constrained, i.e., for a very small B, the model sets high prices => demand is low => allocation satisfies the demand exactly\n",
    "- With increasing supply => the prices go down => demand goes up => the allocation can continue to satisfy demand\n",
    "- With a very high supply, the wasteage starts going up\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749247cc",
   "metadata": {
    "id": "749247cc"
   },
   "source": [
    "## Compare Optimal Versus Actual Net Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92429363",
   "metadata": {
    "id": "92429363"
   },
   "source": [
    "Finally, we can run the optimization model for each week in a year and compare the optimal predicted revenue with the actual weekly revenue.\n",
    "Let us assume that there were no wastage costs in the actual weekly number since this information is unknown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba33e0",
   "metadata": {
    "id": "96ba33e0",
    "outputId": "d55f27ab-7352-49dd-f954-843a4df6ae32"
   },
   "outputs": [],
   "source": [
    "# Create a subset of data for the given year and season\n",
    "df_subset = df[(df['year']==year) & (df['peak']==peak_or_not)]\n",
    "df_subset['price_minus_transport'] = df_subset['price'] - df_subset['region'].map(c_transport) \n",
    "dates = sorted(list(set(df_subset.date))) \n",
    "\n",
    "# Run the optimizer for each week\n",
    "actual, optimal, display_figures = [], [], 0\n",
    "for date in dates: \n",
    "    df_date = df_subset[df_subset['date']==date] \n",
    "    weekly_sold = (df_date['units_sold']).values.sum()  \n",
    "    optimal.append(solve_MIQP(weekly_sold, m, budget, variables)[0])\n",
    "    \n",
    "    actual_weekly_revenue = (df_date['units_sold']*(df_date['price_minus_transport'])).values.sum() \n",
    "    actual.append(actual_weekly_revenue) \n",
    "\n",
    "# Plot the two scatter plots\n",
    "fig_comparison, ax_comparison = plt.subplots(1,1) \n",
    "actual_plot = plt.scatter(dates, actual)\n",
    "optimal_plot = plt.scatter(dates, optimal)\n",
    "plt.legend((optimal_plot,actual_plot),('Optimal weekly net revenue','Actual weekly net revenue'),loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "x_ticks_labels = list(dict.fromkeys([date.strftime(\"%B\") for date in  dates])) \n",
    "ax_comparison.set_xticklabels(x_ticks_labels, rotation=20, fontsize=12)\n",
    "ax_comparison.set_xlabel('Date')\n",
    "ax_comparison.set_ylabel('Net revenue in $million')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "difference = [(i - j)/j for i, j in zip(optimal, actual)]\n",
    "print(\"For the average peak season week in %i, the optimal solution yields %f %% more net revenue than the actual supply chain.\"%(year,100*sum(difference)/len(difference)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c053f3",
   "metadata": {
    "id": "f5c053f3"
   },
   "source": [
    "Now, we can compare the price and sales between the optimal solution and actual data for each week. Select a week using the interactive tool and see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf20e93",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "a92a32890a8a4dc395f983c8f21eeabd"
     ]
    },
    "id": "aaf20e93",
    "outputId": "66d55cba-9e15-4ddf-90f5-02807352e1cc"
   },
   "outputs": [],
   "source": [
    "def compare_with_actual(x):\n",
    "    df_date = df_subset[df_subset['date']==x]\n",
    "    weekly_sold = (df_date['units_sold']).values.sum()  \n",
    "    print(weekly_sold)\n",
    "    opt_revenue, opt_solution = solve_MIQP(weekly_sold, m, budget, variables) \n",
    "\n",
    "    df_comparison = df_date.merge(opt_solution, left_on='region', right_on='Region')\n",
    "\n",
    "    df_comparison = df_comparison[['Region','price','Price','units_sold','Sold']]\n",
    "    df_comparison = df_comparison.rename({'price': 'Actual price', 'Price': 'Optimal price','units_sold': 'Actual sold', 'Sold': 'Optimal sold'}, axis=1)\n",
    "    print(df_comparison.sort_values(by='Region').reset_index(drop=True))\n",
    "\n",
    "display_figures = 0\n",
    "print(\"Select a value for the available inventory (B) (in millions):\\n\")\n",
    "interact(compare_with_actual, x=dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d07d2fd",
   "metadata": {
    "id": "8d07d2fd"
   },
   "source": [
    "Notice that for certain weeks and certain regions, the optimizer sets a higher price than the actual price if it foresees that even the dip in demand is worth it. In certain other cases, a lower price is preferred. Overall, the optimal solution rakes in close to 35% more net revenue than the actual case.\n",
    "This analysis demonstrates that the optimal pricing and supply of avocados could improve the efficiency of the avocado supply chain.\n",
    "\n",
    "With the right optimization tools, every day could be game day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0888fb6",
   "metadata": {
    "id": "e0888fb6"
   },
   "source": [
    "Copyright © 2022 Gurobi Optimization, LLC"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
